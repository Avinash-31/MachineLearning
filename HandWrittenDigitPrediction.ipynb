{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36dd259c-66ef-49bd-8541-d537b303e79d",
   "metadata": {},
   "source": [
    "Title of the Project : Hand Written Digit Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688dc6af-344a-4749-bbba-ca35bd3f0d69",
   "metadata": {},
   "source": [
    "Objective : To develop a machine learning model that accurately predicts hand written digits from images with high precision and recall metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403fb856-f349-48f2-a78e-0f46f8d50e57",
   "metadata": {},
   "source": [
    "Data Source\n",
    "Digits dataset from sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a547972d-1ac3-470c-b832-d869e4bb2ed6",
   "metadata": {},
   "source": [
    "Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebc47542-6c93-4567-989c-94909fab14cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36707427-4565-4434-a4a1-aabdb7a3c35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ebc3a01-f34d-45c7-a366-867ca6c44306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d25f02-049b-4642-bc92-81a045d97e11",
   "metadata": {},
   "source": [
    "Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe152d54-31a8-4d05-8049-74d019c84070",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "092b70ac-a52a-404c-9899-57b2a0f7b5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84890878-d6a9-4c7e-a070-4db61721a83b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, axes = plt.subplots(nrows = 1, ncols=4, figsize = (10,3))\n",
    "for ax,image,label in zip(axes, df.images, df.target):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, cmap = plt.cm.gray_r, interpolation = \"nearest\")\n",
    "    ax.set_title(\"Training : %i\" %label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ed175f-0b3d-457f-bdc4-d7cd4f7bce6f",
   "metadata": {},
   "source": [
    "Describe Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b37af50-b406-4005-b86e-8cb682ea6eda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
       " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
       " 'frame': None,\n",
       " 'feature_names': ['pixel_0_0',\n",
       "  'pixel_0_1',\n",
       "  'pixel_0_2',\n",
       "  'pixel_0_3',\n",
       "  'pixel_0_4',\n",
       "  'pixel_0_5',\n",
       "  'pixel_0_6',\n",
       "  'pixel_0_7',\n",
       "  'pixel_1_0',\n",
       "  'pixel_1_1',\n",
       "  'pixel_1_2',\n",
       "  'pixel_1_3',\n",
       "  'pixel_1_4',\n",
       "  'pixel_1_5',\n",
       "  'pixel_1_6',\n",
       "  'pixel_1_7',\n",
       "  'pixel_2_0',\n",
       "  'pixel_2_1',\n",
       "  'pixel_2_2',\n",
       "  'pixel_2_3',\n",
       "  'pixel_2_4',\n",
       "  'pixel_2_5',\n",
       "  'pixel_2_6',\n",
       "  'pixel_2_7',\n",
       "  'pixel_3_0',\n",
       "  'pixel_3_1',\n",
       "  'pixel_3_2',\n",
       "  'pixel_3_3',\n",
       "  'pixel_3_4',\n",
       "  'pixel_3_5',\n",
       "  'pixel_3_6',\n",
       "  'pixel_3_7',\n",
       "  'pixel_4_0',\n",
       "  'pixel_4_1',\n",
       "  'pixel_4_2',\n",
       "  'pixel_4_3',\n",
       "  'pixel_4_4',\n",
       "  'pixel_4_5',\n",
       "  'pixel_4_6',\n",
       "  'pixel_4_7',\n",
       "  'pixel_5_0',\n",
       "  'pixel_5_1',\n",
       "  'pixel_5_2',\n",
       "  'pixel_5_3',\n",
       "  'pixel_5_4',\n",
       "  'pixel_5_5',\n",
       "  'pixel_5_6',\n",
       "  'pixel_5_7',\n",
       "  'pixel_6_0',\n",
       "  'pixel_6_1',\n",
       "  'pixel_6_2',\n",
       "  'pixel_6_3',\n",
       "  'pixel_6_4',\n",
       "  'pixel_6_5',\n",
       "  'pixel_6_6',\n",
       "  'pixel_6_7',\n",
       "  'pixel_7_0',\n",
       "  'pixel_7_1',\n",
       "  'pixel_7_2',\n",
       "  'pixel_7_3',\n",
       "  'pixel_7_4',\n",
       "  'pixel_7_5',\n",
       "  'pixel_7_6',\n",
       "  'pixel_7_7'],\n",
       " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
       "         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
       "         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
       "         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
       "         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
       "         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
       "         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
       "         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
       "         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
       " 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n:Number of Instances: 1797\\n:Number of Attributes: 64\\n:Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n:Missing Attribute Values: None\\n:Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n:Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n|details-start|\\n**References**\\n|details-split|\\n\\n- C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n  Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n  Graduate Studies in Science and Engineering, Bogazici University.\\n- E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n- Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n  Linear dimensionalityreduction using relevance weighted LDA. School of\\n  Electrical and Electronic Engineering Nanyang Technological University.\\n  2005.\\n- Claudio Gentile. A New Approximate Maximal Margin Classification\\n  Algorithm. NIPS. 2000.\\n\\n|details-end|\\n\"}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d4215e-4542-4370-913e-d10aaa259e3c",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b126b1f-d626-4f5c-95b2-880ac2d7c601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 8, 8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Faltten Image\n",
    "df.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0783f210-dc57-4ae4-bdbd-7e722613b059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.],\n",
       "       [ 0.,  0., 13., 15., 10., 15.,  5.,  0.],\n",
       "       [ 0.,  3., 15.,  2.,  0., 11.,  8.,  0.],\n",
       "       [ 0.,  4., 12.,  0.,  0.,  8.,  8.,  0.],\n",
       "       [ 0.,  5.,  8.,  0.,  0.,  9.,  8.,  0.],\n",
       "       [ 0.,  4., 11.,  0.,  1., 12.,  7.,  0.],\n",
       "       [ 0.,  2., 14.,  5., 10., 12.,  0.,  0.],\n",
       "       [ 0.,  0.,  6., 13., 10.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6273ea11-d788-4eb1-9a16-e8856170787b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2215180f-aab4-4216-92a0-7bdeadd13e11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1797"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da5d7c5a-b1eb-4a80-b47a-9e32b2bd86f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = len(df.images)\n",
    "data = df.images.reshape((n_samples,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33e584ba-a5ec-4634-96fb-b52449bd1c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n",
       "       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n",
       "       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n",
       "        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n",
       "       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7e7a8cb-b2f0-4a5b-8bf9-ca3ba4039ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f7e0d32-202a-4643-a908-4486a40a8758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "80aae2b1-18c8-407a-82dd-fb522974513a",
   "metadata": {},
   "source": [
    "Scaling Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84596ab2-4ef1-4217-9dd5-2a94d871dc7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "910c4638-b77e-42ed-8fd7-99cf5bfd6fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4605f81-461e-4474-a608-eb5f0bab75fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9599953b-8554-489a-be84-b106b3b8e0b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.    , 0.    , 0.3125, 0.8125, 0.5625, 0.0625, 0.    , 0.    ,\n",
       "       0.    , 0.    , 0.8125, 0.9375, 0.625 , 0.9375, 0.3125, 0.    ,\n",
       "       0.    , 0.1875, 0.9375, 0.125 , 0.    , 0.6875, 0.5   , 0.    ,\n",
       "       0.    , 0.25  , 0.75  , 0.    , 0.    , 0.5   , 0.5   , 0.    ,\n",
       "       0.    , 0.3125, 0.5   , 0.    , 0.    , 0.5625, 0.5   , 0.    ,\n",
       "       0.    , 0.25  , 0.6875, 0.    , 0.0625, 0.75  , 0.4375, 0.    ,\n",
       "       0.    , 0.125 , 0.875 , 0.3125, 0.625 , 0.75  , 0.    , 0.    ,\n",
       "       0.    , 0.    , 0.375 , 0.8125, 0.625 , 0.    , 0.    , 0.    ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209673fa-5338-41b6-bf1a-cb0e293f29b7",
   "metadata": {},
   "source": [
    "Defining Target Variable(Y) and Feature Variable (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc91cf77-c2c2-4bf8-8370-3243eb5a9342",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b3cb951-fe00-4c9d-92a3-25e45c9649b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ff85b7-bf24-4266-a3a1-86b3734e17bd",
   "metadata": {},
   "source": [
    "Train Test Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7be351c6-c4c9-43bc-9ae4-e5bcc1db14cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7ae004b5-2698-4cda-a977-800735ab8c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,test_x,train_y,test_y = train_test_split(x,y,test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c54824b-972d-438d-8643-f44ac4fb9254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1257, 64), (540, 64), (1257,), (540,))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape,test_x.shape,train_y.shape,test_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42513ac6-6e31-4c49-82b5-5cd8c2701830",
   "metadata": {},
   "source": [
    "Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aba7068f-f877-42ef-a7d3-5f6a636afd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2f233fc7-5132-4efa-a12d-f5db6e0ca752",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "75dc8b6d-ad95-4cbe-b6ed-ebf5606257be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62d9471-971c-4df1-8dd5-76e38dc3490c",
   "metadata": {},
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cebc6e4c-fbc4-491a-8b18-48be14e74321",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bd244aab-818a-402a-9876-055c14b915c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 3, 2, 1, 9, 6, 9, 2, 6, 7, 2, 4, 1, 5, 0, 3, 7, 9, 3, 9, 5, 6,\n",
       "       1, 1, 1, 5, 0, 8, 0, 5, 6, 1, 5, 6, 4, 1, 3, 8, 0, 3, 4, 4, 5, 3,\n",
       "       0, 2, 5, 5, 9, 2, 6, 9, 0, 9, 3, 4, 1, 4, 4, 3, 9, 1, 1, 6, 9, 0,\n",
       "       1, 0, 6, 5, 8, 7, 1, 7, 2, 9, 1, 7, 7, 5, 4, 5, 4, 5, 5, 6, 6, 7,\n",
       "       6, 2, 2, 8, 0, 2, 4, 6, 9, 4, 3, 3, 4, 7, 8, 9, 9, 8, 0, 5, 5, 9,\n",
       "       5, 0, 7, 7, 3, 2, 8, 1, 3, 1, 2, 3, 3, 2, 0, 4, 1, 2, 7, 2, 3, 9,\n",
       "       5, 4, 4, 8, 0, 4, 1, 3, 1, 5, 3, 5, 5, 5, 2, 4, 4, 9, 1, 5, 4, 0,\n",
       "       2, 3, 9, 1, 0, 8, 2, 0, 0, 2, 2, 7, 2, 5, 7, 6, 0, 3, 9, 3, 6, 2,\n",
       "       1, 0, 8, 9, 9, 7, 7, 2, 1, 4, 2, 6, 0, 8, 0, 6, 4, 5, 5, 3, 5, 1,\n",
       "       8, 9, 5, 5, 6, 5, 6, 7, 8, 5, 6, 4, 4, 7, 1, 4, 1, 9, 4, 7, 0, 6,\n",
       "       7, 2, 7, 4, 0, 9, 6, 5, 4, 7, 0, 1, 4, 9, 7, 3, 6, 7, 1, 0, 7, 0,\n",
       "       2, 0, 7, 4, 6, 5, 6, 8, 2, 8, 8, 6, 2, 8, 1, 8, 3, 2, 2, 3, 7, 6,\n",
       "       4, 2, 1, 7, 6, 8, 2, 7, 5, 6, 6, 3, 1, 6, 9, 1, 3, 3, 9, 7, 9, 7,\n",
       "       3, 2, 7, 8, 5, 0, 8, 1, 2, 4, 4, 3, 2, 5, 8, 6, 2, 8, 6, 2, 6, 3,\n",
       "       5, 7, 8, 9, 2, 7, 7, 9, 3, 2, 5, 6, 5, 2, 4, 3, 8, 8, 7, 8, 6, 1,\n",
       "       3, 0, 9, 1, 3, 2, 3, 6, 9, 2, 0, 8, 3, 5, 6, 5, 2, 9, 3, 7, 3, 6,\n",
       "       7, 8, 5, 0, 8, 1, 9, 8, 6, 5, 4, 9, 8, 3, 6, 5, 8, 0, 3, 2, 7, 2,\n",
       "       4, 0, 0, 6, 1, 4, 2, 8, 7, 9, 8, 2, 2, 0, 9, 9, 0, 1, 1, 0, 5, 8,\n",
       "       9, 1, 4, 9, 4, 4, 1, 3, 8, 5, 7, 9, 5, 1, 8, 7, 4, 5, 1, 2, 2, 9,\n",
       "       5, 4, 7, 3, 1, 9, 6, 5, 3, 9, 7, 1, 8, 3, 3, 8, 8, 2, 7, 2, 1, 2,\n",
       "       5, 4, 7, 6, 7, 8, 2, 8, 5, 8, 8, 6, 0, 8, 7, 8, 3, 3, 8, 9, 3, 0,\n",
       "       7, 8, 4, 9, 0, 6, 3, 1, 6, 9, 4, 9, 8, 7, 2, 7, 4, 8, 4, 6, 9, 2,\n",
       "       1, 8, 2, 2, 8, 0, 3, 7, 1, 2, 1, 7, 4, 4, 2, 5, 2, 5, 3, 7, 2, 1,\n",
       "       0, 4, 0, 1, 0, 6, 1, 1, 5, 6, 0, 7, 4, 6, 7, 2, 7, 8, 6, 5, 7, 3,\n",
       "       1, 4, 1, 9, 2, 6, 9, 2, 1, 6, 5, 9])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb1ccff-594a-4b7e-8373-e4b70ec74b68",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "93947dbb-24dd-4c08-ba84-540941016933",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "472a27af-b538-4cf4-af68-155c420a75b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[45,  0,  0,  0,  1,  0,  0,  0,  0,  0],\n",
       "       [ 0, 51,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0, 64,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, 51,  0,  0,  0,  1,  0,  0],\n",
       "       [ 0,  1,  0,  0, 49,  0,  0,  2,  0,  0],\n",
       "       [ 0,  0,  0,  0,  1, 54,  1,  0,  0,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0, 52,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 52,  0,  0],\n",
       "       [ 0,  3,  0,  1,  0,  2,  0,  1, 54,  1],\n",
       "       [ 0,  1,  0,  0,  0,  0,  0,  1,  1, 49]], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_y,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f5ea4308-44ba-4a75-a1cf-f1d1b5b0c214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        46\n",
      "           1       0.91      1.00      0.95        51\n",
      "           2       1.00      1.00      1.00        64\n",
      "           3       0.98      0.98      0.98        52\n",
      "           4       0.96      0.94      0.95        52\n",
      "           5       0.96      0.95      0.96        57\n",
      "           6       0.98      1.00      0.99        52\n",
      "           7       0.91      1.00      0.95        52\n",
      "           8       0.98      0.87      0.92        62\n",
      "           9       0.96      0.94      0.95        52\n",
      "\n",
      "    accuracy                           0.96       540\n",
      "   macro avg       0.97      0.97      0.96       540\n",
      "weighted avg       0.97      0.96      0.96       540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcd1139-6971-4d55-ab09-b06c249a0cc2",
   "metadata": {},
   "source": [
    "Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a3479b-9452-4e0e-979a-a882ff1015de",
   "metadata": {},
   "source": [
    "To predict handwritten digits using RandomForestClassifier, we first train the model on a dataset of handwritten digits along with their corresponding labels. Once the model is trained, we can use it to predict the labels of new handwritten digit images.\n",
    "\n",
    "To evaluate the performance of the RandomForestClassifier model, we can use a confusion matrix and classification report.\n",
    "\n",
    "Confusion matrix: A confusion matrix is a table that is often used to describe the performance of a classification model on a set of test data for which the true values are known. Each row of the matrix represents the instances in a predicted class while each column represents the instances in an actual class.\n",
    "\n",
    "Classification report: A classification report displays the precision, recall, F1-score, and support for each class in the dataset. It provides a more detailed summary of the model's performance than just looking at accuracy alone.\n",
    "\n",
    "By analyzing the confusion matrix and classification report, we can get a better understanding of how well the RandomForestClassifier model is performing in predicting handwritten digits and identify any areas where it may be struggling. This can help us make improvements to the model or the training data to enhance its performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
